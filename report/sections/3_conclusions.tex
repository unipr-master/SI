\section{Conclusioni}
L’analisi dei 200000 campioni provenienti dal training set di EMBER è stata condotta seguendo la metodologia appena illustrata. Poiché ogni variabile utilizzata nelle regole ASP assume come dominio un singolo valore (estratto direttamente dal campione), l’operazione di grounding si è rivelata computazionalmente sostenibile; tuttavia, completare l’elaborazione di tutti i campioni ha richiesto 15 ore e 22 minuti su un processore AMD EPYC 7282 a 2,8 GHz. Inoltre, l'accuratezza del sistema nel classificare i campioni è stata del 75\%. La metodologia non ha quindi prodotto miglioramenti apprezzabili rispetto alla soglia del 70\% fissata per la selezione degli alberi; tuttavia, il vantaggio più significativo risiede nell’aumentato controllo sul sistema, trasformando le black-box, costituite dagli alberi di decisione, in una white-box, rappresentata dal programma ASP.

Un sistema basato su Answer Set Programming, infatti, rende più agevoli le operazioni di manutenzione e di aggiornamento dell’intero sistema decisionale (ricordiamo che il programma completo conta circa 2500 righe di codice ASP). Grazie al formalismo dell’ASP, la rappresentazione che ne deriva offre poi un’elevata flessibilità nell’arricchire o modificare le regole, semplificando al contempo la verifica e la tracciabilità delle scelte. Inoltre, questa struttura favorisce l’integrazione con conoscenze provenienti da altre fonti o da diverse metodologie di ragionamento, garantendo una gestione più trasparente e controllata del processo decisionale.

\section{Sviluppi Futuri}
Per migliorare l’accuratezza del sistema, invece di affidarsi ai tradizionali alberi di decisione, è possibile adottare altre tecniche di intelligenza artificiale spiegabile. Gli algoritmi di induzione di regole (Rule Induction), come RIPPER (Repeated Incremental Pruning to Produce Error Reduction), operano in modo iterativo e producono regole per una classe alla volta, ottimizzandole attraverso potature ripetute. In alternativa, metodi di interpretabilità locale come LIME e SHAP forniscono spiegazioni per singole predizioni, invece di generare regole valide per l’intero dataset.

L’integrazione tra metodi dichiarativi e approcci di machine learning può ulteriormente evolversi, per esempio inserendo vincoli che migliorino la capacità di ragionamento in contesti reali o favorendo la collaborazione tra più sistemi di intelligenza artificiale in grado di condividere regole e pattern acquisiti nel tempo.

Dal punto di vista computazionale, sebbene il pruning abbia ridotto la complessità dell'albero decisionale, rimane fondamentale implementare meccanismi capaci di eliminare le eventuali ridondanze possono manifestarsi sia all’interno delle singole regole, come illustrato nell'esempio riportato nella Sezione~\ref{subsec:asp_rules}, sia tra regole differenti. 

È inoltre possibile approfondire lo studio di tecniche di integrazione delle regole apprese, ma diventa indispensabile disporre di un solido sistema di feature engineering che permetta di considerare un insieme maggiore di feature senza aumentare in maniera esponenziale il numero di combinazioni possibili.